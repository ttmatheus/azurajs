---
title: Cluster Mode
description: Escale sua aplicaÃ§Ã£o atravÃ©s de mÃºltiplos nÃºcleos de CPU automaticamente para mÃ¡xima performance
icon: Monitor
---

# Cluster Mode ğŸ–¥ï¸

AzuraJS fornece **suporte integrado ao modo cluster** para escalar automaticamente sua aplicaÃ§Ã£o atravÃ©s de todos os nÃºcleos de CPU disponÃ­veis com **zero configuraÃ§Ã£o manual**. O modo cluster melhora drasticamente o throughput e confiabilidade ao executar mÃºltiplas instÃ¢ncias da sua aplicaÃ§Ã£o simultaneamente.

<Callout type="info">
**O que Ã© Cluster Mode?** O modo cluster cria mÃºltiplos processos workers (um por nÃºcleo de CPU) que todos lidam com requisiÃ§Ãµes recebidas. O balanceador de carga do SO distribui o trÃ¡fego uniformemente entre os workers, maximizando a utilizaÃ§Ã£o da CPU.
</Callout>

## Por que Usar Cluster Mode? ğŸ¯

O modo cluster fornece benefÃ­cios significativos para aplicaÃ§Ãµes em produÃ§Ã£o:

### BenefÃ­cios de Performance ğŸ“ˆ
- **Maior throughput**: Lida com 3-15x mais requisiÃ§Ãµes por segundo
- **Melhor utilizaÃ§Ã£o da CPU**: Usa todos os nÃºcleos disponÃ­veis ao invÃ©s de apenas um
- **LatÃªncia reduzida**: Distribui a carga entre mÃºltiplos processos
- **Processamento concorrente**: Lida com mÃºltiplas operaÃ§Ãµes pesadas simultaneamente

### BenefÃ­cios de Confiabilidade ğŸ›¡ï¸
- **RecuperaÃ§Ã£o automÃ¡tica**: Workers crashados sÃ£o automaticamente reiniciados
- **Zero downtime**: Outros workers continuam servindo enquanto um reinicia
- **Isolamento de processos**: Problemas em um worker nÃ£o afetam outros
- **Desligamento gracioso**: Workers finalizam requisiÃ§Ãµes atuais antes de parar

### Quando Ativar âœ…
- âœ… **Ambientes de produÃ§Ã£o** com alto trÃ¡fego
- âœ… **Servidores multi-core** (2+ nÃºcleos de CPU)
- âœ… **OperaÃ§Ãµes intensivas de CPU** (processamento de dados, manipulaÃ§Ã£o de imagem)
- âœ… **Requisitos de alta disponibilidade**
- âœ… **Processos de longa duraÃ§Ã£o** que precisam de resiliÃªncia

### Quando NÃƒO Ativar âŒ
- âŒ **Desenvolvimento/debugging** (processo Ãºnico Ã© mais fÃ¡cil de debugar)
- âŒ **MÃ¡quinas single-core** (sem benefÃ­cio, adiciona overhead)
- âŒ **OrquestraÃ§Ã£o de containers** (Kubernetes/Docker Swarm lidam com escalonamento)
- âŒ **FunÃ§Ãµes serverless** (jÃ¡ escalam automaticamente)
- âŒ **AplicaÃ§Ãµes stateful** sem armazenamento de sessÃ£o externo

## InÃ­cio RÃ¡pido âš¡

### ConfiguraÃ§Ã£o BÃ¡sica

Simplesmente ative o cluster mode no seu arquivo de configuraÃ§Ã£o e AzuraJS cuida de tudo automaticamente:

```typescript title="azura.config.ts"
import type { ConfigTypes } from "azurajs/config";

const config: ConfigTypes = {
  server: {
    port: 3000,
    cluster: true,  // Ativar cluster mode - sÃ³ isso!
  },
};

export default config;
```

SÃ³ isso! Quando `cluster: true` estÃ¡ definido, AzuraJS automaticamente:
- âœ… Detecta o nÃºmero de nÃºcleos de CPU disponÃ­veis
- âœ… Cria um processo worker por nÃºcleo de CPU
- âœ… Distribui conexÃµes entre workers usando round-robin
- âœ… Reinicia automaticamente workers crashados com backoff exponencial
- âœ… Gerencia o desligamento gracioso de todos os workers
- âœ… Gerencia comunicaÃ§Ã£o entre processos
- âœ… Sincroniza configuraÃ§Ã£o entre todos os workers

### Seu CÃ³digo da AplicaÃ§Ã£o Permanece Simples

Nenhuma mudanÃ§a necessÃ¡ria no cÃ³digo da sua aplicaÃ§Ã£o! Suas rotas e controllers funcionam exatamente da mesma forma:

```typescript title="index.ts"
import { AzuraClient } from "azurajs";
import { applyDecorators } from "azurajs/decorators";
import { HomeController } from "./controllers/HomeController";

const app = new AzuraClient();

applyDecorators(app, [HomeController]);

// Isso automaticamente cria workers quando cluster mode estÃ¡ ativado
await app.listen();
```

<Callout type="success">
**Zero MudanÃ§as de CÃ³digo**: Seu cÃ³digo da aplicaÃ§Ã£o permanece idÃªntico independente do cluster mode estar ativado ou nÃ£o. Toda a lÃ³gica de clustering Ã© tratada internamente pelo AzuraJS.
</Callout>

## Como Funciona ğŸ”§

AzuraJS implementa o mÃ³dulo cluster do Node.js internamente com gerenciamento automÃ¡tico de workers e balanceamento de carga inteligente.

### VisÃ£o Geral da Arquitetura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Processo PrimÃ¡rio               â”‚
â”‚  - Cria workers                         â”‚
â”‚  - Monitora saÃºde                       â”‚
â”‚  - Gerencia reinÃ­cios                   â”‚
â”‚  - Lida com sinais                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚          â”‚          â”‚
    â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â” â”Œâ”€â”€â–¼â”€â”€â”€â”€â”€â” â”Œâ”€â”€â–¼â”€â”€â”€â”€â”€â”
    â”‚ Worker 1 â”‚ â”‚Worker 2â”‚ â”‚Worker Nâ”‚
    â”‚(Porta 3k)â”‚ â”‚(Porta 3k)â”‚ â”‚(Porta 3k)â”‚
    â””â”€â”€â”€â”€â”€â–²â”€â”€â”€â”€â”˜ â””â”€â”€â–²â”€â”€â”€â”€â”€â”˜ â””â”€â”€â–²â”€â”€â”€â”€â”€â”˜
          â”‚         â”‚          â”‚
    â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”
    â”‚   Balanceador de Carga do SO   â”‚
    â”‚        (Round-Robin)            â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–²â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
          RequisiÃ§Ãµes do Cliente
```

### Fluxo Interno do Processo

1. **CriaÃ§Ã£o do Processo PrimÃ¡rio**
   - AzuraJS cria um processo primÃ¡rio na inicializaÃ§Ã£o
   - PrimÃ¡rio nÃ£o lida com requisiÃ§Ãµes, apenas gerencia workers

2. **CriaÃ§Ã£o de Workers**
   - Um worker por nÃºcleo de CPU Ã© criado (fork)
   - Cada worker executa uma cÃ³pia completa da sua aplicaÃ§Ã£o
   - Todos os workers escutam na mesma porta (SO lida com isso)

3. **DistribuiÃ§Ã£o de RequisiÃ§Ãµes**
   - Kernel do SO distribui conexÃµes recebidas
   - Algoritmo round-robin garante distribuiÃ§Ã£o uniforme
   - Nenhum worker Ãºnico fica sobrecarregado

4. **Monitoramento de SaÃºde**
   - PrimÃ¡rio monitora saÃºde dos workers via heartbeats
   - Detecta crashes, travamentos e problemas de memÃ³ria
   - Cria automaticamente substitutos para workers falhados

5. **Desligamento Gracioso**
   - PrimÃ¡rio recebe sinal de desligamento (SIGTERM/SIGINT)
   - Workers finalizam requisiÃ§Ãµes atuais
   - Novas requisiÃ§Ãµes rejeitadas durante desligamento
   - TerminaÃ§Ã£o limpa do processo

<Callout type="info">
**Compartilhamento de Porta**: Todos os workers escutam na mesma porta. O kernel do SO lida com distribuir conexÃµes entre workers usando a opÃ§Ã£o de socket SO_REUSEPORT.
</Callout>

<Callout type="success">
**Gerenciamento AutomÃ¡tico**: VocÃª nunca escreve cÃ³digo de clustering vocÃª mesmo. AzuraJS lida com toda a complexidade internamente baseado na sua configuraÃ§Ã£o.
</Callout>

## ConfiguraÃ§Ã£o AvanÃ§ada âš™ï¸

### ConfiguraÃ§Ã£o Baseada em Ambiente

Ative cluster mode apenas em produÃ§Ã£o:

```typescript title="azura.config.ts"
const isProduction = process.env.NODE_ENV === "production";
const isDevelopment = process.env.NODE_ENV === "development";

const config: ConfigTypes = {
  environment: isProduction ? "production" : "development",
  server: {
    port: Number(process.env.PORT) || 3000,
    cluster: isProduction, // Cluster apenas em produÃ§Ã£o
  },
  logging: {
    enabled: true,
    showDetails: isDevelopment, // Logs verbosos apenas em dev
  },
};

export default config;
```

### ConfiguraÃ§Ã£o Completa de ProduÃ§Ã£o

```typescript title="azura.config.ts"
import type { ConfigTypes } from "azurajs/config";

const config: ConfigTypes = {
  environment: "production",
  server: {
    port: process.env.PORT || 3000,
    cluster: true,              // Ativar cluster mode
    ipHost: false,              // Usa 0.0.0.0 para todas as interfaces
  },
  logging: {
    enabled: true,
    showDetails: true,          // Mostra PIDs dos workers nos logs
  },
  plugins: {
    cors: {
      enabled: true,
      origins: ["https://seudominio.com"],
      methods: ["GET", "POST", "PUT", "DELETE", "PATCH"],
      credentials: true,
    },
  },
};

export default config;
```

## Gerenciamento de Estado Compartilhado e Dados ğŸ’¾

**CrÃ­tico**: Workers executam em **processos separados** e **NÃƒO compartilham memÃ³ria**. Este Ã© o conceito mais importante para entender ao usar cluster mode.

### Entendendo Isolamento de Processos

Cada worker Ã© um processo Node.js completamente separado com seu prÃ³prio:
- EspaÃ§o de memÃ³ria
- Escopo de variÃ¡veis
- Armazenamento de cache
- Descritores de arquivo
- Event loop

<Callout type="danger">
**MemÃ³ria NÃƒO Ã© Compartilhada**: MudanÃ§as em variÃ¡veis em um worker sÃ£o invisÃ­veis para outros workers. Estado em memÃ³ria deve ser armazenado externamente.
</Callout>

### âŒ Anti-PadrÃµes (NÃ£o Funcionam Entre Workers)

#### Cache em MemÃ³ria
```typescript
// âŒ RUIM: Cada worker tem seu prÃ³prio cache
const cache = new Map();

@Get("/data/:id")
getData(@Param("id") id: string, @Res() res: ResponseServer) {
  if (cache.has(id)) {
    // SÃ³ funciona se o mesmo worker lidar com a requisiÃ§Ã£o
    return res.json(cache.get(id));
  }
  
  const data = fetchFromDatabase(id);
  cache.set(id, data); // Armazenado apenas NESTE worker
  res.json(data);
}
```

**Problema**: Worker 1 faz cache dos dados, mas Workers 2-4 nÃ£o verÃ£o. Todo worker busca do banco independentemente.

#### Armazenamento de SessÃ£o em MemÃ³ria
```typescript
// âŒ RUIM: SessÃµes nÃ£o compartilhadas entre workers
const sessions = new Map<string, UserSession>();

app.use((req, res, next) => {
  const sessionId = req.cookies['session-id'];
  req.session = sessions.get(sessionId); // Pode nÃ£o existir neste worker
  next();
});
```

**Problema**: UsuÃ¡rio faz login no Worker 1, prÃ³xima requisiÃ§Ã£o vai para o Worker 2 que nÃ£o tem a sessÃ£o.

#### Contadores e EstatÃ­sticas
```typescript
// âŒ RUIM: Cada worker tem contador separado
let requestCount = 0;

app.use((req, res, next) => {
  requestCount++; // SÃ³ incrementa NESTE worker
  next();
});

@Get("/stats")
getStats() {
  return { requests: requestCount }; // Mostra apenas a contagem deste worker
}
```

**Problema**: Contagem total de requisiÃ§Ãµes requer somar todos os workers, nÃ£o Ã© possÃ­vel com armazenamento em memÃ³ria.

### âœ… PadrÃµes Corretos (Funcionam com Cluster Mode)

#### Redis para Cache Compartilhado

```typescript
import Redis from "ioredis";
const redis = new Redis({
  host: process.env.REDIS_HOST || "localhost",
  port: 6379,
  retryStrategy: (times) => Math.min(times * 50, 2000),
});

@Get("/data/:id")
async getData(@Param("id") id: string, @Res() res: ResponseServer) {
  // Verificar cache primeiro
  const cached = await redis.get(`data:${id}`);
  if (cached) {
    return res.json(JSON.parse(cached));
  }
  
  // Buscar do banco de dados
  const data = await fetchFromDatabase(id);
  
  // Cache para todos os workers
  await redis.setex(`data:${id}`, 3600, JSON.stringify(data));
  
  res.json(data);
}
```

**BenefÃ­cios**:
- âœ… Todos os workers compartilham o mesmo cache
- âœ… Acesso rÃ¡pido em memÃ³ria via Redis
- âœ… ExpiraÃ§Ã£o automÃ¡tica
- âœ… PersistÃªncia entre reinÃ­cios

#### Redis para Gerenciamento de SessÃµes

```typescript
import RedisStore from "connect-redis";
import session from "express-session";
import Redis from "ioredis";

const redisClient = new Redis();

app.use(session({
  store: new RedisStore({ client: redisClient }),
  secret: process.env.SESSION_SECRET,
  resave: false,
  saveUninitialized: false,
  cookie: {
    secure: process.env.NODE_ENV === "production",
    httpOnly: true,
    maxAge: 1000 * 60 * 60 * 24, // 24 horas
  },
}));

// Agora sessÃµes funcionam entre todos os workers
@Get("/profile")
getProfile(@Req() req: RequestServer, @Res() res: ResponseServer) {
  if (!req.session.userId) {
    return res.status(401).json({ error: "NÃ£o autenticado" });
  }
  
  res.json({ userId: req.session.userId });
}
```

#### Banco de Dados para Dados Persistentes

```typescript
import { PrismaClient } from "@prisma/client";
const prisma = new PrismaClient();

@Post("/analytics/track")
async trackEvent(@Body() event: AnalyticsEvent, @Res() res: ResponseServer) {
  // Banco de dados Ã© compartilhado entre todos os workers
  await prisma.analyticsEvent.create({
    data: {
      userId: event.userId,
      eventType: event.type,
      metadata: event.metadata,
      timestamp: new Date(),
    },
  });
  
  res.status(201).json({ success: true });
}

@Get("/analytics/stats")
async getStats(@Res() res: ResponseServer) {
  // Agregar dados de todas as contribuiÃ§Ãµes dos workers
  const stats = await prisma.analyticsEvent.groupBy({
    by: ['eventType'],
    _count: { id: true },
  });
  
  res.json({ stats });
}
```

#### Filas de Mensagens para ComunicaÃ§Ã£o Entre Workers

```typescript
import Bull from "bull";

const emailQueue = new Bull("email", {
  redis: {
    host: "localhost",
    port: 6379,
  },
});

// Qualquer worker pode adicionar jobs
@Post("/send-email")
async sendEmail(@Body() emailData: EmailData, @Res() res: ResponseServer) {
  await emailQueue.add("send", emailData);
  res.json({ status: "enfileirado" });
}

// Jobs sÃ£o processados pelos workers disponÃ­veis
emailQueue.process("send", async (job) => {
  await sendEmailViaProvider(job.data);
});
```

### SoluÃ§Ãµes Recomendadas para Estado Compartilhado

| Caso de Uso | SoluÃ§Ã£o | Biblioteca |
|-------------|---------|-----------|
| **Caching** | Redis | `ioredis`, `redis` |
| **SessÃµes** | Redis Store | `connect-redis` |
| **Banco de Dados** | PostgreSQL/MySQL | `prisma`, `typeorm` |
| **Document Store** | MongoDB | `mongoose`, `mongodb` |
| **Fila de Jobs** | Bull/BullMQ | `bull`, `bullmq` |
| **Pub/Sub** | Redis Pub/Sub | `ioredis` |
| **Tempo Real** | Redis Adapter | `socket.io-redis` |
| **Armazenamento de Arquivos** | S3/Cloud Storage | `@aws-sdk/client-s3` |

<Callout type="tip">
**Melhor PrÃ¡tica**: Projete sua aplicaÃ§Ã£o para ser stateless. Armazene todo estado externamente para que qualquer worker possa lidar com qualquer requisiÃ§Ã£o.
</Callout>

### Abordagem HÃ­brida: Cache Local do Worker com Fallback Redis

```typescript
import Redis from "ioredis";
import NodeCache from "node-cache";

// Cache L1: Local do worker (rÃ¡pido, nÃ£o compartilhado)
const localCache = new NodeCache({ stdTTL: 60 }); // 60 segundos TTL

// Cache L2: Redis (compartilhado entre workers)
const redis = new Redis();

@Get("/product/:id")
async getProduct(@Param("id") id: string, @Res() res: ResponseServer) {
  // Tentar cache L1 primeiro (mais rÃ¡pido)
  let product = localCache.get<Product>(id);
  if (product) {
    return res.json({ product, source: "L1-cache" });
  }
  
  // Tentar cache L2 (Redis)
  const cached = await redis.get(`product:${id}`);
  if (cached) {
    product = JSON.parse(cached);
    localCache.set(id, product); // Popular L1 para prÃ³xima vez
    return res.json({ product, source: "L2-cache" });
  }
  
  // Buscar do banco de dados
  product = await prisma.product.findUnique({ where: { id } });
  
  // Popular ambos os caches
  localCache.set(id, product);
  await redis.setex(`product:${id}`, 300, JSON.stringify(product));
  
  res.json({ product, source: "database" });
}
```

**BenefÃ­cios da Abordagem HÃ­brida**:
- âš¡ **Ultra-rÃ¡pido**: Cache L1 serve em microssegundos
- ğŸ”„ **Compartilhado**: Cache L2 reduz carga do banco entre todos os workers
- ğŸ“Š **Eficiente**: O melhor dos dois mundos


## BenefÃ­cios de Performance e Benchmarks ğŸ“ˆ

O modo cluster fornece melhorias significativas de performance ao utilizar todos os nÃºcleos de CPU disponÃ­veis.

### Melhorias de Throughput Esperadas

| NÃºcleos CPU | Aumento de Throughput | Caso de Uso |
|-------------|----------------------|-------------|
| 2 cores     | ~1.7-1.9x           | VPS pequeno, servidores bÃ¡sicos |
| 4 cores     | ~3.2-3.7x           | InstÃ¢ncias cloud padrÃ£o |
| 8 cores     | ~6.0-7.2x           | Servidores de alta performance |
| 16 cores    | ~11-14x             | Servidores dedicados |
| 32 cores    | ~20-26x             | Servidores enterprise |

<Callout type="info">
**Nota**: Ganhos de performance reais dependem das caracterÃ­sticas da sua aplicaÃ§Ã£o, padrÃµes de I/O e tipo de workload.
</Callout>

### Fatores que Afetam a Performance

#### I/O-Bound vs CPU-Bound

```typescript
// OperaÃ§Ãµes CPU-Bound (se beneficiam mais do clustering)
@Get("/compute/:number")
async computeFactorial(@Param("number") n: string) {
  // Trabalho pesado de CPU
  let result = 1;
  for (let i = 1; i <= Number(n); i++) {
    result *= i;
  }
  return { result };
}

// OperaÃ§Ãµes I/O-Bound (se beneficiam menos, mas ainda Ãºtil)
@Get("/users/:id")
async getUser(@Param("id") id: string) {
  // Tempo de espera de I/O domina
  const user = await database.user.findUnique({
    where: { id },
    include: { posts: true, comments: true }
  });
  return { user };
}
```

**CaracterÃ­sticas de Performance**:
- **CPU-Bound**: Escalonamento quase linear com cores (8 cores = ~7-8x performance)
- **I/O-Bound**: Ganhos mais modestos (8 cores = ~2-4x performance)
- **Workload Misto**: Tipicamente 4-6x melhoria com 8 cores

### Exemplo de Benchmark Real

```bash
# Processo Ãšnico (1 worker)
$ ab -n 10000 -c 100 http://localhost:3000/api/users
Requests per second:    1,250 [#/sec]

# Cluster Mode (8 workers em mÃ¡quina 8-core)
$ ab -n 10000 -c 100 http://localhost:3000/api/users
Requests per second:    7,800 [#/sec]
# 6.2x de melhoria!
```

### ConsideraÃ§Ãµes de MemÃ³ria

Cada worker consome memÃ³ria, entÃ£o monitore seu uso:

```typescript
// Cada worker carrega a aplicaÃ§Ã£o completa
@Controller("/api")
class ApiController {
  // Estes dados sÃ£o duplicados em cada worker
  private readonly config = loadConfig();
  private readonly cache = new Map(); // Cache por worker
}
```

**FÃ³rmula de MemÃ³ria**:
```
MemÃ³ria Total = MemÃ³ria Base Ã— NÃºmero de Workers
```

**Exemplo**: Se um processo usa 150MB:
- 4 workers = ~600MB
- 8 workers = ~1.2GB
- 16 workers = ~2.4GB

<Callout type="warn">
**Planejamento de MemÃ³ria**: Garanta que seu servidor tem RAM suficiente. Uma boa regra: `(MemÃ³ria do Processo Ãšnico Ã— NÃºcleos CPU) + 20% buffer`
</Callout>

### DistribuiÃ§Ã£o de Carga

AzuraJS usa o balanceamento de carga round-robin do kernel do SO:

```
DistribuiÃ§Ã£o de RequisiÃ§Ãµes ao Longo do Tempo:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Worker 1: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  â”‚ 25.3%
â”‚ Worker 2: â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  â”‚ 24.8%
â”‚ Worker 3: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  â”‚ 25.1%
â”‚ Worker 4: â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  â”‚ 24.8%
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## OrquestraÃ§Ã£o de Containers (Docker, Kubernetes) ğŸ³

Ao usar plataformas de orquestraÃ§Ã£o de containers, **desative o cluster mode** e deixe o orquestrador lidar com o escalonamento.

### Por que Desativar Cluster Mode com OrquestraÃ§Ã£o?

<Callout type="warn">
**Importante**: Usar cluster mode dentro de containers Ã© redundante e pode causar problemas:
- Orquestradores jÃ¡ distribuem carga entre containers
- Escalonamento duplo adiciona complexidade desnecessÃ¡ria
- Torna debugging e monitoramento mais difÃ­ceis
- Consome mais recursos que o necessÃ¡rio
</Callout>

### ConfiguraÃ§Ã£o Recomendada para Containers

```typescript title="azura.config.ts"
// Ambientes de container: um processo por container
const config: ConfigTypes = {
  server: {
    port: 3000,
    cluster: false,  // Desativar - deixe o orquestrador escalar
    ipHost: false,   // Bind em 0.0.0.0 para networking de container
  },
  logging: {
    enabled: true,
    showDetails: false, // Logs mais simples para agregaÃ§Ã£o de container
  },
};

export default config;
```

### Escalonamento com Docker Compose

```yaml title="docker-compose.yml"
version: '3.8'

services:
  api:
    build: .
    image: myapp:latest
    environment:
      - NODE_ENV=production
      - PORT=3000
    deploy:
      replicas: 4  # Rodar 4 containers ao invÃ©s de cluster mode
      resources:
        limits:
          cpus: '1'     # Cada container recebe 1 CPU
          memory: 512M
        reservations:
          cpus: '0.5'
          memory: 256M
  
  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
    depends_on:
      - api
```

### Deployment Kubernetes

```yaml title="k8s-deployment.yml"
apiVersion: apps/v1
kind: Deployment
metadata:
  name: azurajs-app
  labels:
    app: azurajs
spec:
  replicas: 4  # Kubernetes gerencia 4 pods
  selector:
    matchLabels:
      app: azurajs
  template:
    metadata:
      labels:
        app: azurajs
    spec:
      containers:
      - name: app
        image: myapp:latest
        ports:
        - containerPort: 3000
        env:
        - name: NODE_ENV
          value: "production"
        resources:
          requests:
            memory: "256Mi"
            cpu: "500m"
          limits:
            memory: "512Mi"
            cpu: "1000m"
        livenessProbe:
          httpGet:
            path: /health
            port: 3000
          initialDelaySeconds: 10
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /health
            port: 3000
          initialDelaySeconds: 5
          periodSeconds: 5
---
apiVersion: v1
kind: Service
metadata:
  name: azurajs-service
spec:
  selector:
    app: azurajs
  ports:
  - protocol: TCP
    port: 80
    targetPort: 3000
  type: LoadBalancer
```

### Horizontal Pod Autoscaler

```yaml title="k8s-hpa.yml"
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: azurajs-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: azurajs-app
  minReplicas: 2
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
```

### ComparaÃ§Ã£o: Cluster Mode vs OrquestraÃ§Ã£o de Containers

| Aspecto | Cluster Mode | OrquestraÃ§Ã£o de Containers |
|---------|--------------|---------------------------|
| **Unidade de Escala** | Processo | Container/Pod |
| **Gerenciamento** | AzuraJS | Kubernetes/Docker |
| **Isolamento de Recursos** | SO compartilhado | Containers isolados |
| **Rolling Updates** | Manual | Integrado |
| **Health Checks** | BÃ¡sico | AvanÃ§ado |
| **Auto-scaling** | Fixo (nÃºcleos CPU) | DinÃ¢mico (HPA) |
| **Melhor Para** | Servidor Ãºnico | Clusters multi-servidor |

## Monitoramento e Observabilidade ğŸ‘€

### Logging Integrado

Ative logging detalhado para monitorar comportamento dos workers:

```typescript title="azura.config.ts"
const config: ConfigTypes = {
  server: {
    cluster: true,
  },
  logging: {
    enabled: true,
    showDetails: true,  // Mostra PIDs dos workers e eventos do ciclo de vida
  },
};
```

### Logs de InicializaÃ§Ã£o

```bash
[Primary] Iniciando AzuraJS em cluster mode...
[Primary] Criando 8 workers para 8 nÃºcleos CPU
[Worker 1] Servidor ouvindo na porta 3000 (PID: 12345)
[Worker 2] Servidor ouvindo na porta 3000 (PID: 12346)
[Worker 3] Servidor ouvindo na porta 3000 (PID: 12347)
[Worker 4] Servidor ouvindo na porta 3000 (PID: 12348)
[Worker 5] Servidor ouvindo na porta 3000 (PID: 12349)
[Worker 6] Servidor ouvindo na porta 3000 (PID: 12350)
[Worker 7] Servidor ouvindo na porta 3000 (PID: 12351)
[Worker 8] Servidor ouvindo na porta 3000 (PID: 12352)
[Primary] Todos os workers iniciados com sucesso
```

### Logs de ReinÃ­cio de Worker

```bash
[Primary] Worker 3 (PID: 12347) crashou com cÃ³digo 1
[Primary] Iniciando worker substituto...
[Worker 9] Servidor ouvindo na porta 3000 (PID: 12360)
[Primary] SubstituiÃ§Ã£o de worker bem-sucedida
```

### Logs de Desligamento Gracioso

```bash
^C[Primary] SIGINT recebido, iniciando desligamento gracioso...
[Primary] Enviando sinal de desligamento para todos os workers
[Worker 1] Finalizando requisiÃ§Ãµes atuais...
[Worker 2] Finalizando requisiÃ§Ãµes atuais...
[Worker 3] Finalizando requisiÃ§Ãµes atuais...
[Worker 4] Finalizando requisiÃ§Ãµes atuais...
[Worker 1] Desligado graciosamente (PID: 12345)
[Worker 2] Desligado graciosamente (PID: 12346)
[Worker 3] Desligado graciosamente (PID: 12347)
[Worker 4] Desligado graciosamente (PID: 12348)
[Primary] Todos os workers parados. Saindo.
```

### Monitoramento Customizado de Workers

```typescript
import os from "os";

@Get("/health")
async healthCheck(@Res() res: ResponseServer) {
  const memUsage = process.memoryUsage();
  
  res.json({
    status: "healthy",
    worker: {
      pid: process.pid,
      uptime: process.uptime(),
      memory: {
        rss: `${Math.round(memUsage.rss / 1024 / 1024)}MB`,
        heapUsed: `${Math.round(memUsage.heapUsed / 1024 / 1024)}MB`,
        heapTotal: `${Math.round(memUsage.heapTotal / 1024 / 1024)}MB`,
      },
    },
    system: {
      cpus: os.cpus().length,
      freeMem: `${Math.round(os.freemem() / 1024 / 1024)}MB`,
      totalMem: `${Math.round(os.totalmem() / 1024 / 1024)}MB`,
      loadAvg: os.loadavg(),
    },
  });
}
```

### IntegraÃ§Ã£o com Ferramentas de Monitoramento

```typescript
// MÃ©tricas Prometheus para monitoramento de cluster
import promClient from "prom-client";

// Criar um histogram para duraÃ§Ã£o de requisiÃ§Ãµes por worker
const httpRequestDuration = new promClient.Histogram({
  name: "http_request_duration_seconds",
  help: "DuraÃ§Ã£o de requisiÃ§Ãµes HTTP em segundos",
  labelNames: ["method", "route", "status_code", "worker_id"],
});

app.use((req, res, next) => {
  const start = Date.now();
  
  res.on("finish", () => {
    const duration = (Date.now() - start) / 1000;
    httpRequestDuration
      .labels(req.method, req.route?.path || req.url, res.statusCode.toString(), process.pid.toString())
      .observe(duration);
  });
  
  next();
});

@Get("/metrics")
async getMetrics(@Res() res: ResponseServer) {
  res.set("Content-Type", promClient.register.contentType);
  res.send(await promClient.register.metrics());
}
```


## Melhores PrÃ¡ticas e RecomendaÃ§Ãµes âœ¨

### EstratÃ©gia Desenvolvimento vs ProduÃ§Ã£o

```typescript title="azura.config.ts"
const isDevelopment = process.env.NODE_ENV === "development";
const isProduction = process.env.NODE_ENV === "production";

const config: ConfigTypes = {
  environment: process.env.NODE_ENV || "development",
  server: {
    port: Number(process.env.PORT) || 3000,
    cluster: isProduction && !process.env.DISABLE_CLUSTER, // Controle flexÃ­vel
  },
  logging: {
    enabled: true,
    showDetails: isDevelopment, // Verboso em dev, conciso em prod
  },
};

export default config;
```

<Callout type="tip">
**Desenvolvimento**: Mantenha `cluster: false` para debugging mais fÃ¡cil com um Ãºnico processo. Hot reload e breakpoints funcionam melhor.
</Callout>

<Callout type="success">
**ProduÃ§Ã£o**: Ative `cluster: true` para maximizar performance e confiabilidade em servidores multi-core.
</Callout>

### Design para Statelessness

```typescript
// âœ… BOM: Design stateless
@Controller("/api/cart")
class CartController {
  constructor(private readonly redis: Redis) {}
  
  @Post("/items")
  async addItem(@Body() item: CartItem, @Req() req: RequestServer) {
    const userId = req.user.id;
    
    // Armazenar no Redis (disponÃ­vel para todos os workers)
    await this.redis.sadd(`cart:${userId}`, JSON.stringify(item));
    
    return { success: true };
  }
  
  @Get("/items")
  async getItems(@Req() req: RequestServer) {
    const userId = req.user.id;
    
    // Recuperar do Redis
    const items = await this.redis.smembers(`cart:${userId}`);
    return { items: items.map(JSON.parse) };
  }
}

// âŒ RUIM: Design stateful
const userCarts = new Map<string, CartItem[]>(); // NÃ£o funciona entre workers

@Post("/items")
addItem(@Body() item: CartItem, @Req() req: RequestServer) {
  const userId = req.user.id;
  const cart = userCarts.get(userId) || [];
  cart.push(item);
  userCarts.set(userId, cart); // Apenas neste worker!
}
```

### Melhores PrÃ¡ticas de Armazenamento Externo

```typescript
// Connection pooling para banco de dados
import { PrismaClient } from "@prisma/client";

// Criar um client por worker (nÃ£o por requisiÃ§Ã£o!)
const prisma = new PrismaClient({
  datasources: {
    db: {
      url: process.env.DATABASE_URL,
    },
  },
  log: process.env.NODE_ENV === "development" ? ["query", "error"] : ["error"],
});

// Redis com reconexÃ£o automÃ¡tica
import Redis from "ioredis";

const redis = new Redis({
  host: process.env.REDIS_HOST || "localhost",
  port: Number(process.env.REDIS_PORT) || 6379,
  password: process.env.REDIS_PASSWORD,
  retryStrategy: (times) => {
    const delay = Math.min(times * 50, 2000);
    return delay;
  },
  maxRetriesPerRequest: 3,
});

// Tratar eventos de conexÃ£o Redis
redis.on("error", (err) => {
  console.error("Erro de conexÃ£o Redis:", err);
});

redis.on("connect", () => {
  console.log(`[Worker ${process.pid}] Conectado ao Redis`);
});
```

### ImplementaÃ§Ã£o de Health Check

```typescript
@Get("/health")
async healthCheck(@Res() res: ResponseServer) {
  const checks = {
    status: "healthy",
    timestamp: new Date().toISOString(),
    worker: {
      pid: process.pid,
      uptime: Math.floor(process.uptime()),
    },
  };
  
  // Verificar conectividade Redis
  try {
    await redis.ping();
    checks.redis = "connected";
  } catch (error) {
    checks.redis = "disconnected";
    checks.status = "unhealthy";
  }
  
  // Verificar conectividade do banco de dados
  try {
    await prisma.$queryRaw`SELECT 1`;
    checks.database = "connected";
  } catch (error) {
    checks.database = "disconnected";
    checks.status = "unhealthy";
  }
  
  const statusCode = checks.status === "healthy" ? 200 : 503;
  res.status(statusCode).json(checks);
}
```

### Tratamento de Erros Gracioso

```typescript
// Handler de erro global
app.use((error, req, res, next) => {
  console.error(`[Worker ${process.pid}] Erro:`, error);
  
  res.status(error.status || 500).json({
    error: {
      message: process.env.NODE_ENV === "production" 
        ? "Erro interno do servidor" 
        : error.message,
      worker: process.pid,
    },
  });
});

// Handler de exceÃ§Ã£o nÃ£o capturada
process.on("uncaughtException", (error) => {
  console.error(`[Worker ${process.pid}] ExceÃ§Ã£o nÃ£o capturada:`, error);
  // Deixe o AzuraJS reiniciar este worker
  process.exit(1);
});

// RejeiÃ§Ã£o de promise nÃ£o tratada
process.on("unhandledRejection", (reason, promise) => {
  console.error(`[Worker ${process.pid}] RejeiÃ§Ã£o nÃ£o tratada:`, reason);
  // Opcionalmente sair para acionar reinÃ­cio
  process.exit(1);
});
```

## ResoluÃ§Ã£o de Problemas Comuns ğŸ”

### Problema: Workers Continuam Crashando

**Sintomas**:
```bash
[Primary] Worker 3 (PID: 12347) crashou com cÃ³digo 1
[Primary] Worker 5 (PID: 12360) crashou com cÃ³digo 1
[Primary] Worker 7 (PID: 12375) crashou com cÃ³digo 1
```

**Causas Comuns**:
1. **ExceÃ§Ãµes NÃ£o Capturadas**: Erros nÃ£o tratados causando terminaÃ§Ã£o do processo
2. **Vazamentos de MemÃ³ria**: Worker fica sem memÃ³ria
3. **Problemas de Banco de Dados**: Problemas de conexÃ£o ou falhas em queries
4. **DependÃªncias Faltando**: MÃ³dulos necessÃ¡rios nÃ£o instalados

**SoluÃ§Ãµes**:
```typescript
// Adicionar tratamento de erros abrangente
process.on("uncaughtException", (error) => {
  console.error("ExceÃ§Ã£o NÃ£o Capturada:", error);
  // Log para serviÃ§o externo
  logger.error("ExceÃ§Ã£o nÃ£o capturada", { error, pid: process.pid });
  // Desligar graciosamente
  setTimeout(() => process.exit(1), 1000);
});

process.on("unhandledRejection", (reason) => {
  console.error("RejeiÃ§Ã£o NÃ£o Tratada:", reason);
  logger.error("RejeiÃ§Ã£o nÃ£o tratada", { reason, pid: process.pid });
});

// Envolver operaÃ§Ãµes async
@Get("/data")
async getData(@Res() res: ResponseServer) {
  try {
    const data = await fetchFromDatabase();
    res.json(data);
  } catch (error) {
    console.error("Erro ao buscar dados:", error);
    res.status(500).json({ error: "Falha ao buscar dados" });
  }
}
```

### Problema: Comportamento Inconsistente Entre RequisiÃ§Ãµes

**Sintomas**: Mesma requisiÃ§Ã£o retorna resultados diferentes ou sessÃ£o de usuÃ¡rio perdida

**Causa**: Usando estado em memÃ³ria que nÃ£o Ã© compartilhado entre workers

**SoluÃ§Ã£o**: Mover todo estado para armazenamento externo

```typescript
// âŒ CÃ³digo ProblemÃ¡tico
const cache = new Map();

@Get("/config")
getConfig() {
  if (!cache.has("config")) {
    cache.set("config", loadConfig()); // Apenas neste worker
  }
  return cache.get("config");
}

// âœ… CÃ³digo Corrigido
import Redis from "ioredis";
const redis = new Redis();

@Get("/config")
async getConfig() {
  let config = await redis.get("config");
  if (!config) {
    config = JSON.stringify(loadConfig());
    await redis.setex("config", 3600, config); // Compartilhado entre workers
  }
  return JSON.parse(config);
}
```

### Problema: Porta JÃ¡ em Uso

**Sintomas**:
```bash
Error: listen EADDRINUSE: address already in use :::3000
```

**Causas**:
1. Outra aplicaÃ§Ã£o usando a porta
2. MÃºltiplas instÃ¢ncias do AzuraJS rodando
3. InstÃ¢ncia anterior nÃ£o desligou corretamente

**SoluÃ§Ãµes**:
```bash
# Verificar o que estÃ¡ usando a porta
lsof -i :3000          # macOS/Linux
netstat -ano | findstr :3000  # Windows

# Matar o processo
kill -9 <PID>          # macOS/Linux
taskkill /PID <PID> /F # Windows

# Ou usar uma porta diferente
PORT=3001 npm start
```

### Problema: Alto Uso de MemÃ³ria

**Sintomas**: Consumo de memÃ³ria cresce com o tempo, sistema fica lento

**Causas**:
1. Vazamentos de memÃ³ria no cÃ³digo da aplicaÃ§Ã£o
2. Muitos workers para a RAM disponÃ­vel
3. Caches grandes em memÃ³ria

**SoluÃ§Ãµes**:
```typescript
// Monitorar uso de memÃ³ria
@Get("/metrics/memory")
getMemoryMetrics() {
  const usage = process.memoryUsage();
  return {
    worker: process.pid,
    rss: `${Math.round(usage.rss / 1024 / 1024)}MB`,
    heapUsed: `${Math.round(usage.heapUsed / 1024 / 1024)}MB`,
    heapTotal: `${Math.round(usage.heapTotal / 1024 / 1024)}MB`,
    external: `${Math.round(usage.external / 1024 / 1024)}MB`,
  };
}

// Implementar limites de memÃ³ria
import v8 from "v8";

const heapStats = v8.getHeapStatistics();
const maxHeap = heapStats.heap_size_limit;

setInterval(() => {
  const usage = process.memoryUsage();
  if (usage.heapUsed > maxHeap * 0.9) {
    console.warn(`Worker ${process.pid} aproximando limite de memÃ³ria`);
    // Acionar garbage collection se necessÃ¡rio
    if (global.gc) {
      global.gc();
    }
  }
}, 30000); // Verificar a cada 30 segundos
```

### Problema: Pool de ConexÃµes do Banco de Dados Esgotado

**Sintomas**:
```bash
Error: Connection pool timeout
Error: Too many connections
```

**Causa**: Cada worker cria suas prÃ³prias conexÃµes de banco de dados

**SoluÃ§Ã£o**: Ajustar tamanho do pool de conexÃµes

```typescript
// Calcular tamanho apropriado do pool
const numWorkers = require("os").cpus().length;
const connectionsPerWorker = 10; // Ajustar baseado nas suas necessidades
const totalConnections = numWorkers * connectionsPerWorker;

// Configurar Prisma
const prisma = new PrismaClient({
  datasources: {
    db: {
      url: process.env.DATABASE_URL,
    },
  },
  // Prisma gerencia automaticamente o tamanho do pool, mas vocÃª pode ajustar
  log: ["error"],
});

// Para outros ORMs como TypeORM
const dataSource = new DataSource({
  type: "postgres",
  host: "localhost",
  port: 5432,
  database: "mydb",
  poolSize: 10, // Por worker
  // Total de conexÃµes = poolSize Ã— numWorkers
});

// Garantir que o banco de dados pode lidar com o total de conexÃµes
// PostgreSQL max_connections deve ser > total de conexÃµes
```

## Dicas de OtimizaÃ§Ã£o de Performance âš¡

### 1. Otimizar Contagem de Workers

```typescript
import os from "os";

// PadrÃ£o: um worker por core
const numCPUs = os.cpus().length;

// Para apps com muito I/O: pode se beneficiar de mais workers
const ioHeavyWorkers = numCPUs * 2;

// Para apps com muito CPU: manter contagem de cores
const cpuHeavyWorkers = numCPUs;

// Para sistemas com memÃ³ria limitada: menos workers
const availableMemoryMB = os.totalmem() / 1024 / 1024;
const memoryPerWorkerMB = 512; // Estimativa
const maxWorkersByMemory = Math.floor(availableMemoryMB / memoryPerWorkerMB);
```

### 2. Habilitar HTTP Keep-Alive

```typescript
import http from "http";

// Configurar keep-alive
const server = http.createServer((req, res) => {
  res.setHeader("Connection", "keep-alive");
  res.setHeader("Keep-Alive", "timeout=5, max=1000");
  // Seu handler
});

server.keepAliveTimeout = 5000; // 5 segundos
server.headersTimeout = 6000; // Deve ser > keepAliveTimeout
```

### 3. Usar Cache Estrategicamente

```typescript
// Exemplo: Cache de computaÃ§Ãµes caras
import NodeCache from "node-cache";

const cache = new NodeCache({ 
  stdTTL: 600, // 10 minutos
  checkperiod: 120, // Verificar chaves expiradas a cada 2 minutos
  useClones: false, // Melhor performance, mas modifique com cuidado
});

@Get("/expensive-data")
async getExpensiveData(@Res() res: ResponseServer) {
  const cacheKey = "expensive_data";
  
  // Verificar cache local do worker primeiro
  let data = cache.get(cacheKey);
  if (data) {
    return res.json({ data, cached: true });
  }
  
  // Computar resultado caro
  data = await performExpensiveOperation();
  cache.set(cacheKey, data);
  
  res.json({ data, cached: false });
}
```

### 4. OtimizaÃ§Ã£o de Queries do Banco de Dados

```typescript
// Usar connection pooling
// Implementar cache de resultados de queries
// Usar Ã­ndices no banco de dados

@Get("/users/:id")
async getUser(@Param("id") id: string) {
  // Cache de queries do banco no Redis
  const cached = await redis.get(`user:${id}`);
  if (cached) return JSON.parse(cached);
  
  const user = await prisma.user.findUnique({
    where: { id },
    select: { 
      id: true, 
      name: true, 
      email: true,
      // Apenas selecionar campos necessÃ¡rios
    },
  });
  
  await redis.setex(`user:${id}`, 300, JSON.stringify(user));
  return user;
}
```

## PrÃ³ximos Passos e Recursos ğŸ“–

<Cards>
  <Card 
    title="ConfiguraÃ§Ã£o" 
    href="/docs/pt/configuration" 
    description="Explore todas as opÃ§Ãµes de configuraÃ§Ã£o para ajuste fino"
  />
  <Card 
    title="OtimizaÃ§Ã£o de Performance" 
    href="/docs/pt/performance" 
    description="TÃ©cnicas avanÃ§adas para maximizar performance"
  />
  <Card 
    title="Tratamento de Erros" 
    href="/docs/pt/error-handling" 
    description="Implemente estratÃ©gias robustas de tratamento de erros"
  />
  <Card 
    title="Guia de Deploy" 
    href="/docs/pt/deployment" 
    description="FaÃ§a deploy em produÃ§Ã£o com confianÃ§a"
  />
</Cards>

### Recursos Adicionais

- **DocumentaÃ§Ã£o Redis**: https://redis.io/docs/
- **MÃ³dulo Cluster do Node.js**: https://nodejs.org/api/cluster.html
- **Melhores PrÃ¡ticas Kubernetes**: https://kubernetes.io/docs/concepts/configuration/
- **EstratÃ©gias de Load Balancing**: https://nginx.org/en/docs/http/load_balancing.html

### ConclusÃµes Principais

1. âœ… **Ative em ProduÃ§Ã£o**: Use cluster mode em servidores de produÃ§Ã£o multi-core
2. âœ… **Armazenamento Externo**: Sempre armazene estado compartilhado em Redis/bancos de dados
3. âœ… **Monitore Workers**: Acompanhe memÃ³ria, CPU e saÃºde de cada worker
4. âœ… **Design Stateless**: Construa aplicaÃ§Ãµes que funcionam em qualquer worker
5. âœ… **ConsciÃªncia de Containers**: Desative ao usar Kubernetes/Docker Swarm
6. âœ… **Teste Completamente**: Garanta que sua aplicaÃ§Ã£o funciona corretamente em cluster mode

<Callout type="success">
**ParabÃ©ns!** VocÃª agora entende como usar efetivamente o cluster mode do AzuraJS para construir aplicaÃ§Ãµes escalÃ¡veis e de alta performance. Lembre-se: cluster mode Ã© poderoso mas requer gerenciamento adequado de estado e monitoramento.
</Callout>
