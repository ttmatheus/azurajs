---
title: Performance
description: Otimize sua aplica√ß√£o AzuraJS para m√°ximo desempenho
icon: Lightbulb
---

# Performance üí°

Aprenda t√©cnicas e melhores pr√°ticas para maximizar o desempenho da sua aplica√ß√£o AzuraJS.

## Cluster Mode üñ•Ô∏è

A maneira mais eficaz de melhorar o desempenho √© ativar cluster mode - simplesmente defina na configura√ß√£o e AzuraJS cuida de tudo automaticamente:

```typescript title="azura.config.ts"
import type { ConfigTypes } from "azurajs/config";

const config: ConfigTypes = {
  server: {
    cluster: true,  // AzuraJS utiliza automaticamente todos os n√∫cleos da CPU
  },
};

export default config;
```

**Ganhos esperados:**
- 4 cores: ~3.5x throughput
- 8 cores: ~7x throughput
- 16 cores: ~14x throughput

**Nenhum c√≥digo manual necess√°rio** - AzuraJS automaticamente cria workers, distribui carga e gerencia crashes.

Veja o [guia completo de Cluster Mode](/docs/pt/cluster-mode) para todos os detalhes.

## Caching Estrat√©gico üíæ

### Cache em Mem√≥ria

```typescript
const cache = new Map<string, { data: any; expires: number }>();

function cacheMiddleware(ttl: number) {
  return (req: RequestServer, res: ResponseServer, next: () => void) => {
    if (req.method !== "GET") {
      return next();
    }
    
    const key = req.url;
    const cached = cache.get(key);
    
    // Verificar cache
    if (cached && Date.now() < cached.expires) {
      return res.json(cached.data);
    }
    
    // Interceptar resposta
    const originalJson = res.json.bind(res);
    res.json = function(data: any) {
      cache.set(key, { data, expires: Date.now() + ttl });
      return originalJson(data);
    };
    
    next();
  };
}

// Cache de 5 minutos para dados p√∫blicos
app.use("/api/public", cacheMiddleware(300000));
```

### Cache com Redis

```typescript
import { createClient } from "redis";

const redis = createClient();
await redis.connect();

async function redisCacheMiddleware(
  req: RequestServer,
  res: ResponseServer,
  next: () => void
) {
  if (req.method !== "GET") {
    return next();
  }
  
  const key = `cache:${req.url}`;
  
  try {
    const cached = await redis.get(key);
    
    if (cached) {
      return res.json(JSON.parse(cached));
    }
    
    const originalJson = res.json.bind(res);
    res.json = async function(data: any) {
      await redis.setEx(key, 300, JSON.stringify(data));
      return originalJson(data);
    };
    
    next();
  } catch (error) {
    next();  // Falhar aberto
  }
}

app.use(redisCacheMiddleware);
```

## Otimiza√ß√£o de Banco de Dados üóÑÔ∏è

### Connection Pooling

```typescript
import { Pool } from "pg";

const pool = new Pool({
  host: "localhost",
  port: 5432,
  database: "mydb",
  user: "user",
  password: "password",
  max: 20,  // M√°ximo de 20 conex√µes
  idleTimeoutMillis: 30000,
  connectionTimeoutMillis: 2000
});

@Get("/users")
async getUsers() {
  const client = await pool.connect();
  try {
    const result = await client.query("SELECT * FROM users");
    return { users: result.rows };
  } finally {
    client.release();
  }
}
```

### Query Optimization

```typescript
// ‚ùå N+1 Query Problem
async function getBadPosts() {
  const posts = await db.query("SELECT * FROM posts");
  
  for (const post of posts) {
    post.author = await db.query("SELECT * FROM users WHERE id = $1", [post.authorId]);
  }
  
  return posts;
}

// ‚úÖ Single Query with JOIN
async function getGoodPosts() {
  const posts = await db.query(`
    SELECT posts.*, users.name as author_name, users.email as author_email
    FROM posts
    LEFT JOIN users ON posts.author_id = users.id
  `);
  
  return posts;
}
```

### √çndices

```sql
-- Criar √≠ndices para queries frequentes
CREATE INDEX idx_users_email ON users(email);
CREATE INDEX idx_posts_author_id ON posts(author_id);
CREATE INDEX idx_posts_created_at ON posts(created_at DESC);

-- √çndice composto para queries espec√≠ficas
CREATE INDEX idx_posts_status_created ON posts(status, created_at DESC);
```

## Pagina√ß√£o Eficiente üìÑ

```typescript
interface PaginationQuery {
  page: number;
  limit: number;
  sortBy?: string;
  sortOrder?: "asc" | "desc";
}

@Get("/posts")
async getPosts(@Query() query: PaginationQuery) {
  const page = Math.max(1, query.page || 1);
  const limit = Math.min(100, Math.max(1, query.limit || 10));
  const offset = (page - 1) * limit;
  const sortBy = query.sortBy || "created_at";
  const sortOrder = query.sortOrder || "desc";
  
  // Query com LIMIT e OFFSET
  const posts = await db.query(`
    SELECT * FROM posts
    ORDER BY ${sortBy} ${sortOrder}
    LIMIT $1 OFFSET $2
  `, [limit, offset]);
  
  // Count total (pode ser cacheado)
  const total = await db.query("SELECT COUNT(*) FROM posts");
  
  return {
    posts,
    pagination: {
      page,
      limit,
      total: total.rows[0].count,
      totalPages: Math.ceil(total.rows[0].count / limit)
    }
  };
}
```

## Compression üóúÔ∏è

```typescript
import { gzipSync } from "zlib";

function compressionMiddleware(req: RequestServer, res: ResponseServer, next: () => void) {
  const acceptEncoding = req.headers["accept-encoding"] || "";
  
  if (!acceptEncoding.includes("gzip")) {
    return next();
  }
  
  const originalJson = res.json.bind(res);
  const originalSend = res.send.bind(res);
  
  res.json = function(data: any) {
    const json = JSON.stringify(data);
    const compressed = gzipSync(json);
    
    res.setHeader("Content-Encoding", "gzip");
    res.setHeader("Content-Type", "application/json");
    return originalSend(compressed);
  };
  
  next();
}

app.use(compressionMiddleware);
```

## Lazy Loading üîÑ

```typescript
// Carregar apenas o necess√°rio
@Get("/posts/:id")
async getPost(@Param("id") id: string, @Query("include") include: string) {
  const post = await db.query("SELECT * FROM posts WHERE id = $1", [id]);
  
  // Carregar relacionamentos apenas se solicitado
  if (include?.includes("author")) {
    post.author = await db.query("SELECT * FROM users WHERE id = $1", [post.authorId]);
  }
  
  if (include?.includes("comments")) {
    post.comments = await db.query("SELECT * FROM comments WHERE post_id = $1", [post.id]);
  }
  
  return { post };
}
```

## Rate Limiting Inteligente üõ°Ô∏è

```typescript
// Rate limit mais alto para usu√°rios autenticados
function smartRateLimit(req: RequestServer, res: ResponseServer, next: () => void) {
  const isAuthenticated = !!req.user;
  
  const limit = isAuthenticated ? 1000 : 100;  // 10x mais para usu√°rios autenticados
  const windowMs = 60000;  // 1 minuto
  
  const key = isAuthenticated ? `auth:${req.user.id}` : `anon:${req.ip}`;
  
  // Implementar rate limiting com limite din√¢mico
  const allowed = checkRateLimit(key, windowMs, limit);
  
  if (!allowed) {
    return res.status(429).json({ error: "Rate limit excedido" });
  }
  
  next();
}
```

## Async/Await vs Promises.all üîÄ

```typescript
// ‚ùå Lento - Execu√ß√£o sequencial
async function slowFetch() {
  const users = await fetchUsers();      // Espera 100ms
  const posts = await fetchPosts();      // Espera 100ms
  const comments = await fetchComments();  // Espera 100ms
  // Total: 300ms
  
  return { users, posts, comments };
}

// ‚úÖ R√°pido - Execu√ß√£o paralela
async function fastFetch() {
  const [users, posts, comments] = await Promise.all([
    fetchUsers(),      // Executa em paralelo
    fetchPosts(),      // Executa em paralelo
    fetchComments()    // Executa em paralelo
  ]);
  // Total: 100ms (tempo da opera√ß√£o mais lenta)
  
  return { users, posts, comments };
}
```

## Streaming üåä

Para respostas grandes, use streaming:

```typescript
import { createReadStream } from "fs";

@Get("/download/large-file")
downloadFile(@Res() res: ResponseServer) {
  const stream = createReadStream("./large-file.csv");
  
  res.setHeader("Content-Type", "text/csv");
  res.setHeader("Content-Disposition", "attachment; filename=data.csv");
  
  stream.pipe(res);
}
```

## Evitar Bloqueio da Event Loop üîÑ

```typescript
// ‚ùå Ruim - Bloqueia event loop
@Get("/heavy")
heavyComputation() {
  let result = 0;
  for (let i = 0; i < 10000000000; i++) {
    result += i;
  }
  return { result };
}

// ‚úÖ Bom - Usa worker threads
import { Worker } from "worker_threads";

@Get("/heavy")
async heavyComputation() {
  return new Promise((resolve, reject) => {
    const worker = new Worker("./heavy-worker.js");
    
    worker.on("message", resolve);
    worker.on("error", reject);
    worker.on("exit", (code) => {
      if (code !== 0) {
        reject(new Error(`Worker stopped with exit code ${code}`));
      }
    });
  });
}

// heavy-worker.js
const { parentPort } = require("worker_threads");

let result = 0;
for (let i = 0; i < 10000000000; i++) {
  result += i;
}

parentPort.postMessage({ result });
```

## Benchmarking üìä

Use ferramentas para medir desempenho:

```bash
# Autocannon (Node.js)
npm install -g autocannon
autocannon -c 100 -d 10 http://localhost:3000/api/users

# Apache Bench
ab -n 10000 -c 100 http://localhost:3000/api/users

# wrk
wrk -t12 -c400 -d30s http://localhost:3000/api/users
```

### Exemplo de Benchmark

```typescript
import autocannon from "autocannon";

async function benchmark() {
  const result = await autocannon({
    url: "http://localhost:3000",
    connections: 100,
    duration: 10,
    pipelining: 1,
    requests: [
      {
        method: "GET",
        path: "/api/users"
      }
    ]
  });
  
  console.log(`Requests/sec: ${result.requests.mean}`);
  console.log(`Latency (avg): ${result.latency.mean}ms`);
  console.log(`Throughput: ${result.throughput.mean} bytes/sec`);
}

benchmark();
```

## Monitoramento üìà

```typescript
import { performance } from "perf_hooks";

function performanceMiddleware(req: RequestServer, res: ResponseServer, next: () => void) {
  const start = performance.now();
  
  res.on("finish", () => {
    const duration = performance.now() - start;
    
    console.log({
      method: req.method,
      url: req.url,
      statusCode: res.statusCode,
      duration: `${duration.toFixed(2)}ms`
    });
    
    // Alertar se requisi√ß√£o demorar muito
    if (duration > 1000) {
      console.warn(`‚ö†Ô∏è Slow request: ${req.method} ${req.url} took ${duration.toFixed(2)}ms`);
    }
  });
  
  next();
}

app.use(performanceMiddleware);
```

## Otimiza√ß√µes de Produ√ß√£o üöÄ

### Vari√°veis de Ambiente

```typescript
const app = new AzuraClient({
  environment: "production",
  logging: {
    level: process.env.NODE_ENV === "production" ? "error" : "debug"
  }
});
```

### PM2 Configuration

```javascript
// ecosystem.config.js
module.exports = {
  apps: [{
    name: "azura-app",
    script: "./dist/server.js",
    instances: "max",  // Usar todos os cores
    exec_mode: "cluster",
    env_production: {
      NODE_ENV: "production",
      PORT: 3000
    },
    max_memory_restart: "500M",
    error_file: "./logs/error.log",
    out_file: "./logs/out.log",
    log_date_format: "YYYY-MM-DD HH:mm:ss Z"
  }]
};
```

## Checklist de Performance ‚úÖ

<Callout type="tip">
  ‚úÖ **Usar cluster mode** para utilizar todos os cores da CPU
</Callout>

<Callout type="tip">
  ‚úÖ **Implementar caching** para dados que n√£o mudam frequentemente
</Callout>

<Callout type="tip">
  ‚úÖ **Otimizar queries de banco** com √≠ndices e JOINs adequados
</Callout>

<Callout type="tip">
  ‚úÖ **Usar connection pooling** para banco de dados
</Callout>

<Callout type="tip">
  ‚úÖ **Comprimir respostas** com gzip
</Callout>

<Callout type="tip">
  ‚úÖ **Paginar resultados** para limitar dados transferidos
</Callout>

<Callout type="tip">
  ‚úÖ **Usar Promise.all** para opera√ß√µes paralelas
</Callout>

<Callout type="tip">
  ‚úÖ **Monitorar desempenho** com m√©tricas e logs
</Callout>

<Callout type="warn">
  ‚ö†Ô∏è **Evitar bloqueio da event loop** com opera√ß√µes s√≠ncronas pesadas
</Callout>

<Callout type="warn">
  ‚ö†Ô∏è **N√£o fazer queries N+1** - sempre usar JOINs ou batch queries
</Callout>

## Compara√ß√£o de Performance üìä

**Servidor √∫nico vs Cluster (8 cores):**

```
Single Process:
  Requests/sec: 5,000
  Latency: 20ms

Cluster Mode (8 cores):
  Requests/sec: 35,000
  Latency: 3ms
  
Ganho: 7x throughput, 6.6x lat√™ncia
```

## Benchmarks Reais üìä

### AzuraJS vs Frameworks Populares

Condi√ß√µes do benchmark: Intel i7 8-core, 16GB RAM, Node.js 20.x, wrk -t12 -c400 -d30s

| Framework | Req/sec | Lat√™ncia (m√©dia) | Lat√™ncia (p99) | Mem√≥ria (MB) |
|-----------|---------|------------------|----------------|--------------|
| **AzuraJS (cluster)** | **35,000** | **3ms** | **15ms** | **120** |
| Express.js | 12,000 | 8ms | 45ms | 180 |
| Fastify | 28,000 | 4ms | 18ms | 140 |
| Hono | 32,000 | 3.5ms | 16ms | 110 |
| Elysia (Bun) | 40,000 | 2.5ms | 12ms | 95 |

### Endpoint GET Simples

```typescript
// C√≥digo do benchmark
@Get('/hello')
hello() {
  return { message: 'Hello World' };
}
```

**Resultados:**
```bash
$ wrk -t12 -c400 -d30s http://localhost:3000/hello

Executando teste de 30s @ http://localhost:3000/hello
  12 threads e 400 conex√µes
  
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency     3.12ms    2.45ms   89.12ms   87.23%
    Req/Sec     2.91k   345.12    4.23k    73.45%
    
  1,047,234 requisi√ß√µes em 30.01s, 215.43MB lidos
  
Requests/sec:  34,907.12
Transfer/sec:      7.18MB
```

### Endpoint API JSON

```typescript
@Get('/users/:id')
async getUser(@Param('id') id: string) {
  const user = await db.query('SELECT * FROM users WHERE id = $1', [id]);
  return { user };
}
```

**Com Connection Pool:**
- Requests/sec: 15,000
- Lat√™ncia (m√©dia): 8ms
- Lat√™ncia (p99): 35ms

**Com Cache Redis:**
- Requests/sec: 28,000
- Lat√™ncia (m√©dia): 4ms
- Lat√™ncia (p99): 18ms

## Profiling de CPU üî¨

### Usando Node.js Inspector

```bash
# Iniciar com inspector
node --inspect server.js

# Ou usar --inspect-brk para pausar no in√≠cio
node --inspect-brk server.js

# Depois abrir Chrome DevTools
chrome://inspect
```

### Profiling Program√°tico

```bash
npm install v8-profiler-next
```

```typescript
import profiler from 'v8-profiler-next';
import { writeFileSync } from 'fs';

// Iniciar profiling
function startProfiling() {
  profiler.startProfiling('CPU Profile', true);
  log.info('Profiling de CPU iniciado');
}

// Parar e salvar perfil
function stopProfiling() {
  const profile = profiler.stopProfiling('CPU Profile');
  
  profile.export((error, result) => {
    writeFileSync('cpu-profile.cpuprofile', result);
    profile.delete();
    log.info('Perfil de CPU salvo em cpu-profile.cpuprofile');
  });
}

// Fazer perfil de endpoint espec√≠fico
@Get('/api/heavy')
async heavyOperation() {
  startProfiling();
  
  try {
    const result = await performHeavyOperation();
    return { result };
  } finally {
    stopProfiling();
  }
}
```

### Analisando com Clinic.js

```bash
npm install -g clinic

# Diagnosticar problemas de performance
clinic doctor -- node server.js

# Fazer perfil de uso de CPU
clinic flame -- node server.js

# Analisar opera√ß√µes ass√≠ncronas
clinic bubbleprof -- node server.js
```

### Flame Graphs

```bash
# Instalar 0x
npm install -g 0x

# Gerar flame graph
0x server.js

# Fazer teste de carga durante o profiling
# Em outro terminal:
autocannon -c 100 -d 30 http://localhost:3000

# Abrir flamegraph.html no navegador
```

## Gerenciamento de Mem√≥ria üß†

### Heap Snapshots

```typescript
import v8 from 'v8';
import { writeFileSync } from 'fs';

function takeHeapSnapshot(filename: string) {
  const snapshot = v8.writeHeapSnapshot(filename);
  log.info(`Snapshot de heap salvo em ${snapshot}`);
}

// Fazer snapshot sob demanda
@Get('/admin/heap-snapshot')
heapSnapshot() {
  const filename = `heap-${Date.now()}.heapsnapshot`;
  takeHeapSnapshot(filename);
  return { success: true, filename };
}

// Auto-snapshot em mem√≥ria alta
setInterval(() => {
  const usage = process.memoryUsage();
  const heapUsedMB = usage.heapUsed / 1024 / 1024;
  
  if (heapUsedMB > 500) {  // Limite de 500MB
    log.warn(`Uso alto de mem√≥ria: ${heapUsedMB.toFixed(2)}MB`);
    takeHeapSnapshot(`auto-heap-${Date.now()}.heapsnapshot`);
  }
}, 60000);  // Verificar a cada minuto
```

### Detec√ß√£o de Memory Leaks

```typescript
class MemoryMonitor {
  private samples: number[] = [];
  private readonly maxSamples = 10;
  
  check() {
    const usage = process.memoryUsage();
    const heapUsedMB = usage.heapUsed / 1024 / 1024;
    
    this.samples.push(heapUsedMB);
    
    if (this.samples.length > this.maxSamples) {
      this.samples.shift();
    }
    
    // Detectar crescimento consistente
    if (this.samples.length === this.maxSamples) {
      const isGrowing = this.samples.every((val, i, arr) => 
        i === 0 || val > arr[i - 1]
      );
      
      if (isGrowing) {
        log.fatal('üö® Poss√≠vel memory leak detectado!', {
          samples: this.samples.map(s => `${s.toFixed(2)}MB`),
          current: `${heapUsedMB.toFixed(2)}MB`
        });
        
        // Fazer snapshot para an√°lise
        takeHeapSnapshot(`leak-${Date.now()}.heapsnapshot`);
      }
    }
  }
  
  report() {
    const usage = process.memoryUsage();
    
    return {
      heapUsed: `${(usage.heapUsed / 1024 / 1024).toFixed(2)} MB`,
      heapTotal: `${(usage.heapTotal / 1024 / 1024).toFixed(2)} MB`,
      external: `${(usage.external / 1024 / 1024).toFixed(2)} MB`,
      rss: `${(usage.rss / 1024 / 1024).toFixed(2)} MB`,
      arrayBuffers: `${(usage.arrayBuffers / 1024 / 1024).toFixed(2)} MB`
    };
  }
}

const memoryMonitor = new MemoryMonitor();

// Verificar a cada 5 minutos
setInterval(() => {
  memoryMonitor.check();
  log.info('Uso de mem√≥ria', memoryMonitor.report());
}, 300000);
```

### Monitoramento de Garbage Collection

```typescript
import { PerformanceObserver } from 'perf_hooks';

const obs = new PerformanceObserver((items) => {
  const entry = items.getEntries()[0];
  const duration = entry.duration;
  
  if (duration > 100) {  // Pausa GC > 100ms
    log.warn('Pausa longa de GC detectada', {
      duration: `${duration.toFixed(2)}ms`,
      kind: entry.detail?.kind,
      flags: entry.detail?.flags
    });
  }
});

obs.observe({ entryTypes: ['gc'], buffered: true });

// Garbage collection manual (requer flag --expose-gc)
if (global.gc) {
  @Get('/admin/gc')
  triggerGC() {
    const before = process.memoryUsage().heapUsed;
    global.gc();
    const after = process.memoryUsage().heapUsed;
    const freed = (before - after) / 1024 / 1024;
    
    return {
      freedMemory: `${freed.toFixed(2)}MB`,
      heapUsed: `${(after / 1024 / 1024).toFixed(2)}MB`
    };
  }
}
```

## Ferramentas de Monitoramento üìà

### Endpoint de M√©tricas Integrado

```typescript
import { performance } from 'perf_hooks';

class MetricsCollector {
  private metrics = {
    requests: {
      total: 0,
      success: 0,
      errors: 0,
      byMethod: {} as Record<string, number>,
      byStatus: {} as Record<number, number>
    },
    performance: {
      responseTimes: [] as number[],
      avgResponseTime: 0,
      p50: 0,
      p95: 0,
      p99: 0
    },
    system: {
      uptime: 0,
      memory: {},
      cpu: 0
    }
  };
  
  private startTime = Date.now();
  
  recordRequest(method: string, statusCode: number, duration: number) {
    this.metrics.requests.total++;
    
    if (statusCode < 400) {
      this.metrics.requests.success++;
    } else {
      this.metrics.requests.errors++;
    }
    
    this.metrics.requests.byMethod[method] = 
      (this.metrics.requests.byMethod[method] || 0) + 1;
    
    this.metrics.requests.byStatus[statusCode] = 
      (this.metrics.requests.byStatus[statusCode] || 0) + 1;
    
    this.metrics.performance.responseTimes.push(duration);
    
    // Manter apenas os √∫ltimos 1000
    if (this.metrics.performance.responseTimes.length > 1000) {
      this.metrics.performance.responseTimes.shift();
    }
    
    this.updatePerformanceMetrics();
  }
  
  private updatePerformanceMetrics() {
    const times = [...this.metrics.performance.responseTimes].sort((a, b) => a - b);
    
    if (times.length === 0) return;
    
    this.metrics.performance.avgResponseTime = 
      times.reduce((a, b) => a + b, 0) / times.length;
    
    this.metrics.performance.p50 = times[Math.floor(times.length * 0.5)];
    this.metrics.performance.p95 = times[Math.floor(times.length * 0.95)];
    this.metrics.performance.p99 = times[Math.floor(times.length * 0.99)];
  }
  
  getMetrics() {
    const memory = process.memoryUsage();
    const uptime = Date.now() - this.startTime;
    
    return {
      requests: this.metrics.requests,
      performance: {
        avgResponseTime: `${this.metrics.performance.avgResponseTime.toFixed(2)}ms`,
        p50: `${this.metrics.performance.p50.toFixed(2)}ms`,
        p95: `${this.metrics.performance.p95.toFixed(2)}ms`,
        p99: `${this.metrics.performance.p99.toFixed(2)}ms`
      },
      system: {
        uptime: `${(uptime / 1000 / 60).toFixed(2)} minutos`,
        memory: {
          heapUsed: `${(memory.heapUsed / 1024 / 1024).toFixed(2)}MB`,
          heapTotal: `${(memory.heapTotal / 1024 / 1024).toFixed(2)}MB`,
          rss: `${(memory.rss / 1024 / 1024).toFixed(2)}MB`
        },
        nodeVersion: process.version,
        platform: process.platform,
        arch: process.arch
      }
    };
  }
}

const metrics = new MetricsCollector();

// Middleware de m√©tricas
app.use((req, res, next) => {
  const start = performance.now();
  
  res.on('finish', () => {
    const duration = performance.now() - start;
    metrics.recordRequest(req.method, res.statusCode, duration);
  });
  
  next();
});

// Endpoint de m√©tricas
@Get('/metrics')
getMetrics() {
  return metrics.getMetrics();
}

// M√©tricas compat√≠veis com Prometheus
@Get('/metrics/prometheus')
getPrometheusMetrics() {
  const m = metrics.getMetrics();
  
  return `
# HELP http_requests_total Total de requisi√ß√µes HTTP
# TYPE http_requests_total counter
http_requests_total ${m.requests.total}

# HELP http_requests_success Requisi√ß√µes HTTP bem-sucedidas
# TYPE http_requests_success counter
http_requests_success ${m.requests.success}

# HELP http_requests_errors Requisi√ß√µes HTTP com falha
# TYPE http_requests_errors counter
http_requests_errors ${m.requests.errors}

# HELP http_response_time_avg Tempo m√©dio de resposta em ms
# TYPE http_response_time_avg gauge
http_response_time_avg ${parseFloat(m.performance.avgResponseTime)}
  `.trim();
}
```

### Integra√ß√£o com Servi√ßos de Monitoramento

#### Prometheus

```bash
npm install prom-client
```

```typescript
import client from 'prom-client';

// Criar m√©tricas
const httpRequestDuration = new client.Histogram({
  name: 'http_request_duration_ms',
  help: 'Dura√ß√£o das requisi√ß√µes HTTP em ms',
  labelNames: ['method', 'route', 'status_code']
});

const httpRequestTotal = new client.Counter({
  name: 'http_requests_total',
  help: 'N√∫mero total de requisi√ß√µes HTTP',
  labelNames: ['method', 'route', 'status_code']
});

// Middleware
app.use((req, res, next) => {
  const start = Date.now();
  
  res.on('finish', () => {
    const duration = Date.now() - start;
    
    httpRequestDuration.observe(
      { method: req.method, route: req.route?.path || req.url, status_code: res.statusCode },
      duration
    );
    
    httpRequestTotal.inc({
      method: req.method,
      route: req.route?.path || req.url,
      status_code: res.statusCode
    });
  });
  
  next();
});

// Endpoint de m√©tricas
@Get('/metrics')
async metrics() {
  return await client.register.metrics();
}
```

#### DataDog

```bash
npm install dd-trace
```

```typescript
import tracer from 'dd-trace';

tracer.init({
  service: 'azura-api',
  env: process.env.NODE_ENV,
  version: '1.0.0',
  logInjection: true
});

// Tracer instrumenta automaticamente requisi√ß√µes HTTP
```

#### New Relic

```bash
npm install newrelic
```

```typescript
// Deve ser o primeiro import
import 'newrelic';

// Resto da aplica√ß√£o
import { AzuraClient } from 'azurajs';
```

## Checklist de Otimiza√ß√£o para Produ√ß√£o ‚úÖ

### N√≠vel da Aplica√ß√£o

- ‚úÖ Habilitar cluster mode para utiliza√ß√£o multi-core
- ‚úÖ Implementar estrat√©gia de caching (Redis/in-memory)
- ‚úÖ Usar connection pooling para bancos de dados
- ‚úÖ Habilitar compress√£o para respostas
- ‚úÖ Implementar rate limiting
- ‚úÖ Usar pagina√ß√£o para grandes conjuntos de dados
- ‚úÖ Otimizar queries e √≠ndices do banco de dados
- ‚úÖ Implementar lazy loading para relacionamentos
- ‚úÖ Usar Promise.all() para opera√ß√µes paralelas
- ‚úÖ Evitar bloqueio do event loop

### N√≠vel de Infraestrutura

- ‚úÖ Usar load balancer (nginx, HAProxy)
- ‚úÖ Habilitar HTTP/2
- ‚úÖ Configurar CDN para assets est√°ticos
- ‚úÖ Configurar cache de reverse proxy
- ‚úÖ Usar armazenamento SSD
- ‚úÖ Otimizar configura√ß√£o de rede
- ‚úÖ Habilitar conex√µes keep-alive
- ‚úÖ Configurar otimiza√ß√µes no n√≠vel do SO (ulimit, configura√ß√µes TCP)

### Monitoramento & Observabilidade

- ‚úÖ Configurar monitoramento de aplica√ß√£o (DataDog, New Relic)
- ‚úÖ Configurar agrega√ß√£o de logs (ELK, CloudWatch)
- ‚úÖ Implementar rastreamento distribu√≠do
- ‚úÖ Configurar alertas para m√©tricas cr√≠ticas
- ‚úÖ Monitorar taxas e tipos de erro
- ‚úÖ Rastrear m√©tricas de performance (tempos de resposta, throughput)
- ‚úÖ Monitorar uso de recursos (CPU, mem√≥ria, disco)

### Seguran√ßa & Confiabilidade

- ‚úÖ Implementar endpoints de health check
- ‚úÖ Configurar shutdown gracioso
- ‚úÖ Configurar rein√≠cio autom√°tico em crashes (PM2)
- ‚úÖ Implementar circuit breakers
- ‚úÖ Configurar timeouts de requisi√ß√£o
- ‚úÖ Sanitizar inputs de usu√°rio
- ‚úÖ Usar vari√°veis de ambiente para secrets
- ‚úÖ Atualiza√ß√µes regulares de seguran√ßa

## Gargalos Comuns üöß

### 1. Bloqueio do Event Loop

**Problema:**
```typescript
// ‚ùå Ruim: Bloqueia event loop
app.get('/heavy', () => {
  let result = 0;
  for (let i = 0; i < 1000000000; i++) {
    result += i;
  }
  return { result };
});
```

**Solu√ß√£o:**
```typescript
// ‚úÖ Bom: Usar worker threads
import { Worker } from 'worker_threads';

app.get('/heavy', async () => {
  return new Promise((resolve, reject) => {
    const worker = new Worker('./worker.js');
    worker.on('message', resolve);
    worker.on('error', reject);
  });
});
```

### 2. Queries N+1

**Problema:**
```typescript
// ‚ùå Ruim: N+1 queries
const posts = await db.query('SELECT * FROM posts');
for (const post of posts) {
  post.author = await db.query('SELECT * FROM users WHERE id = $1', [post.author_id]);
}
```

**Solu√ß√£o:**
```typescript
// ‚úÖ Bom: Query √∫nica com JOIN
const posts = await db.query(`
  SELECT posts.*, users.name as author_name
  FROM posts
  JOIN users ON posts.author_id = users.id
`);
```

### 3. √çndices Faltando

**Problema:**
```sql
-- Query lenta sem √≠ndice
SELECT * FROM users WHERE email = 'usuario@example.com';
```

**Solu√ß√£o:**
```sql
-- Criar √≠ndice
CREATE INDEX idx_users_email ON users(email);

-- Agora r√°pida!
SELECT * FROM users WHERE email = 'usuario@example.com';
```

### 4. Memory Leaks

**Problema:**
```typescript
// ‚ùå Ruim: Cache sem limite
const cache = new Map();

app.get('/data', (req, res) => {
  cache.set(req.query.key, data);  // Nunca limpo!
});
```

**Solu√ß√£o:**
```typescript
// ‚úÖ Bom: Cache LRU com tamanho m√°ximo
import LRU from 'lru-cache';

const cache = new LRU({
  max: 1000,
  ttl: 1000 * 60 * 5  // 5 minutos
});
```

### 5. Opera√ß√µes Sequenciais

**Problema:**
```typescript
// ‚ùå Ruim: Sequencial (300ms total)
const users = await fetchUsers();  // 100ms
const posts = await fetchPosts();  // 100ms
const comments = await fetchComments();  // 100ms
```

**Solu√ß√£o:**
```typescript
// ‚úÖ Bom: Paralelo (100ms total)
const [users, posts, comments] = await Promise.all([
  fetchUsers(),
  fetchPosts(),
  fetchComments()
]);
```

## Solu√ß√£o de Problemas de Performance üîç

### Alto Uso de CPU

**Diagn√≥stico:**
```bash
# Verificar uso de CPU
top -p $(pgrep -f "node")

# Fazer perfil com 0x
0x server.js
```

**Causas comuns:**
- Computa√ß√£o pesada em manipuladores de requisi√ß√£o
- Algoritmos ineficientes
- Express√µes regulares em strings grandes
- Parsing JSON de payloads grandes

**Solu√ß√µes:**
- Mover computa√ß√£o pesada para worker threads
- Otimizar algoritmos
- Usar streaming para payloads grandes
- Implementar caching

### Alto Uso de Mem√≥ria

**Diagn√≥stico:**
```bash
# Verificar mem√≥ria
node --expose-gc --max-old-space-size=4096 server.js

# Fazer snapshot de heap
curl http://localhost:3000/admin/heap-snapshot
```

**Causas comuns:**
- Memory leaks (listeners, timers, caches)
- Objetos grandes em mem√≥ria
- N√£o liberar conex√µes de banco de dados
- Acumular logs em mem√≥ria

**Solu√ß√µes:**
- Remover event listeners quando terminar
- Limpar timeouts/intervals
- Usar connection pooling
- Implementar rota√ß√£o de logs
- Usar WeakMap/WeakSet para caches

### Tempos de Resposta Lentos

**Diagn√≥stico:**
```bash
# Teste de carga
autocannon -c 100 -d 30 http://localhost:3000

# Verificar tempo de queries
EXPLAIN ANALYZE SELECT * FROM users WHERE email = 'test@example.com';
```

**Causas comuns:**
- Queries lentas no banco de dados
- Falta de caching
- Queries N+1
- Opera√ß√µes bloqueantes

**Solu√ß√µes:**
- Adicionar √≠ndices no banco de dados
- Implementar caching
- Otimizar queries
- Usar Promise.all() para opera√ß√µes paralelas

### Baixo Throughput

**Diagn√≥stico:**
```bash
# Benchmark
wrk -t12 -c400 -d30s http://localhost:3000
```

**Causas comuns:**
- Processo √∫nico (n√£o usando cluster)
- Middleware ineficiente
- Opera√ß√µes s√≠ncronas
- Sem connection pooling

**Solu√ß√µes:**
- Habilitar cluster mode
- Otimizar ordem dos middlewares
- Usar async/await corretamente
- Implementar connection pooling

## Pr√≥ximos Passos üìñ

<Cards>
  <Card title="Cluster Mode" href="cluster-mode" description="Escale em m√∫ltiplos cores" />
  <Card title="Caching" href="caching" description="Implemente estrat√©gias de cache" />
  <Card title="Database" href="database" description="Otimize opera√ß√µes de banco de dados" />
  <Card title="Monitoramento" href="monitoring" description="Monitore sua aplica√ß√£o" />
</Cards>
