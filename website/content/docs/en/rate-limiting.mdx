---
title: Rate Limiting
description: Complete guide to protecting your API from abuse with rate limiting strategies
icon: Shield
---

# Rate Limiting üõ°Ô∏è

Rate limiting is a critical security practice that protects your API from abuse, DDoS attacks, and excessive resource consumption by limiting the number of requests a client can make within a specific time window.

## Why Rate Limiting Matters üéØ

### Protection Against Attacks
- **DDoS Attacks**: Prevent distributed denial-of-service attacks that overwhelm your servers
- **Brute Force**: Limit login attempts to prevent password guessing attacks
- **API Abuse**: Stop malicious actors from scraping or overwhelming your endpoints

### Resource Management
- **Fair Usage**: Ensure all users get fair access to your API resources
- **Cost Control**: Reduce infrastructure costs by preventing excessive API calls
- **Performance**: Maintain consistent response times for all users

### Business Goals
- **Tiered Access**: Implement different limits for free, premium, and enterprise users
- **Monetization**: Encourage upgrades by offering higher limits in paid tiers
- **SLA Compliance**: Meet service level agreements by preventing resource exhaustion

## Rate Limiting Strategies üìä

### 1. Fixed Window
Simple counter that resets at fixed intervals.

**Pros**: Easy to implement, predictable
**Cons**: Allows burst at window boundaries

```typescript
// 100 requests per hour window
// Window: 12:00-13:00, 13:00-14:00, etc.
```

### 2. Sliding Window
More accurate, considers rolling time period.

**Pros**: Prevents boundary bursts, more fair
**Cons**: More complex, requires timestamp tracking

```typescript
// 100 requests in any 60-minute period
// Constantly moving window
```

### 3. Token Bucket
Tokens regenerate at a fixed rate.

**Pros**: Allows controlled bursts, flexible
**Cons**: More complex algorithm

```typescript
// Bucket with 100 tokens
// Refills at 10 tokens/minute
// Each request costs 1 token
```

### 4. Leaky Bucket
Requests processed at a constant rate.

**Pros**: Smooth traffic flow, prevents spikes
**Cons**: May delay legitimate requests

```typescript
// Queue processes 10 requests/second
// Extra requests wait or get rejected
```

## Built-in Rate Limit Plugin üì¶

AzuraJS includes a ready-to-use rate limiting plugin:

```typescript
import { AzuraClient } from "azurajs";

const app = new AzuraClient({
  plugins: {
    rateLimit: {
      enabled: true,
      windowMs: 60000,  // 1 minute
      max: 100,  // 100 requests per window
      message: "Too many requests. Please try again later.",
      statusCode: 429,
      headers: true  // Add X-RateLimit-* headers
    }
  }
});
```

## Plugin Configuration üö®

### Available Options

```typescript
interface RateLimitOptions {
  enabled: boolean;          // Enable/disable
  windowMs: number;          // Time window (ms)
  max: number;               // Maximum requests per window
  message?: string;          // Error message
  statusCode?: number;       // Status code (default: 429)
  headers?: boolean;         // Include X-RateLimit-* headers
  skipSuccessfulRequests?: boolean;  // Don't count successful requests
  skipFailedRequests?: boolean;      // Don't count failed requests
  keyGenerator?: (req: RequestServer) => string;  // Generate custom key
  skip?: (req: RequestServer) => boolean;         // Skip rate limit
}
```

### Complete Example

```typescript
const app = new AzuraClient({
  plugins: {
    rateLimit: {
      enabled: true,
      windowMs: 900000,  // 15 minutes
      max: 100,
      message: "You have reached the request limit. Please wait before trying again.",
      statusCode: 429,
      headers: true,
      skipSuccessfulRequests: false,
      skipFailedRequests: true
    }
  }
});
```

## Custom Rate Limiting üõ†Ô∏è

Create custom rate limiting middleware:

```typescript
import type { RequestHandler } from "azurajs/types";

interface RateLimitStore {
  count: number;
  resetTime: number;
}

const store = new Map<string, RateLimitStore>();

export function createRateLimiter(
  limit: number,
  windowMs: number
): RequestHandler {
  return async (req, res, next) => {
    const ip = req.socket.remoteAddress || "unknown";
    const now = Date.now();
    
    let record = store.get(ip);
    
    if (!record || now > record.resetTime) {
      // Create new record
      record = {
        count: 1,
        resetTime: now + windowMs,
      };
      store.set(ip, record);
      await next();
      return;
    }
    
    record.count++;
    
    if (record.count > limit) {
      const retryAfter = Math.ceil((record.resetTime - now) / 1000);
      res.setHeader("Retry-After", retryAfter.toString());
      res.setHeader("X-RateLimit-Limit", limit.toString());
      res.setHeader("X-RateLimit-Remaining", "0");
      res.setHeader("X-RateLimit-Reset", record.resetTime.toString());
      
      res.status(429).json({
        error: "Too many requests",
        retryAfter,
      });
      return;
    }
    
    // Add rate limit headers
    res.setHeader("X-RateLimit-Limit", limit.toString());
    res.setHeader("X-RateLimit-Remaining", (limit - record.count).toString());
    res.setHeader("X-RateLimit-Reset", record.resetTime.toString());
    
    await next();
  };
}

// Usage
const app = new AzuraClient();
app.use(createRateLimiter(100, 60000)); // 100 req/min
```

## Per-Route Rate Limiting üéØ

Apply different limits to different routes:

```typescript
const strictLimiter = createRateLimiter(10, 60000);   // 10 req/min
const normalLimiter = createRateLimiter(100, 60000);  // 100 req/min

// Apply to specific routes
app.post("/api/auth/login", strictLimiter, loginHandler);
app.get("/api/posts", normalLimiter, getPostsHandler);
```

## User-Based Rate Limiting üë§

Rate limit by user ID instead of IP:

```typescript
export function createUserRateLimiter(
  limit: number,
  windowMs: number
): RequestHandler {
  const store = new Map<string, RateLimitStore>();
  
  return async (req, res, next) => {
    // Get user ID from token/session
    const userId = (req as any).user?.id || req.socket.remoteAddress;
    
    if (!userId) {
      await next();
      return;
    }
    
    const now = Date.now();
    let record = store.get(userId);
    
    if (!record || now > record.resetTime) {
      record = {
        count: 1,
        resetTime: now + windowMs,
      };
      store.set(userId, record);
      await next();
      return;
    }
    
    record.count++;
    
    if (record.count > limit) {
      res.status(429).json({ error: "Rate limit exceeded" });
      return;
    }
    
    await next();
  };
}
```

## Tiered Rate Limiting ‚≠ê

Different limits for different user tiers:

```typescript
interface User {
  id: string;
  tier: "free" | "pro" | "enterprise";
}

const rateLimits = {
  free: { limit: 100, window: 3600000 },        // 100/hour
  pro: { limit: 1000, window: 3600000 },        // 1000/hour
  enterprise: { limit: 10000, window: 3600000 }, // 10000/hour
};

export const tieredRateLimiter: RequestHandler = async (req, res, next) => {
  const user = (req as any).user as User | undefined;
  
  if (!user) {
    // Default for anonymous users
    return await createRateLimiter(50, 3600000)(req, res, next);
  }
  
  const config = rateLimits[user.tier];
  return await createRateLimiter(config.limit, config.window)(req, res, next);
};
```

## Distributed Rate Limiting with Redis üî¥

For applications with multiple instances, use Redis:

```typescript
import { createClient } from "redis";

const redis = createClient({ url: "redis://localhost:6379" });
await redis.connect();

function redisRateLimitMiddleware(
  windowMs: number,
  max: number
) {
  return async (req: RequestServer, res: ResponseServer, next: () => void) => {
    const key = `rate-limit:${req.ip}`;
    const now = Date.now();
    
    try {
      // Get current counter
      const data = await redis.get(key);
      let record: RateLimitRecord;
      
      if (!data) {
        // Create new record
        record = { count: 1, resetAt: now + windowMs };
        await redis.setEx(key, Math.ceil(windowMs / 1000), JSON.stringify(record));
        return next();
      }
      
      record = JSON.parse(data);
      
      // Check if window expired
      if (now > record.resetAt) {
        record = { count: 1, resetAt: now + windowMs };
        await redis.setEx(key, Math.ceil(windowMs / 1000), JSON.stringify(record));
        return next();
      }
      
      // Increment counter
      record.count++;
      await redis.setEx(key, Math.ceil((record.resetAt - now) / 1000), JSON.stringify(record));
      
      // Check limit
      if (record.count > max) {
        return res.status(429).json({
          error: "Too many requests",
          retryAfter: Math.ceil((record.resetAt - now) / 1000)
        });
      }
      
      next();
    } catch (error) {
      console.error("Redis rate limit error:", error);
      next();  // Fail open in case of Redis error
    }
  };
}

app.use(redisRateLimitMiddleware(60000, 100));
```

## Rate Limit with Sliding Window üìä

More precise implementation with sliding window:

```typescript
interface SlidingWindowRecord {
  requests: number[];  // Request timestamps
}

const store = new Map<string, SlidingWindowRecord>();

function slidingWindowRateLimit(
  windowMs: number,
  max: number
) {
  return (req: RequestServer, res: ResponseServer, next: () => void) => {
    const key = req.ip;
    const now = Date.now();
    const windowStart = now - windowMs;
    
    let record = store.get(key);
    
    if (!record) {
      record = { requests: [] };
      store.set(key, record);
    }
    
    // Remove old requests
    record.requests = record.requests.filter(timestamp => timestamp > windowStart);
    
    // Add current request
    record.requests.push(now);
    
    // Add headers
    res.setHeader("X-RateLimit-Limit", max.toString());
    res.setHeader("X-RateLimit-Remaining", Math.max(0, max - record.requests.length).toString());
    
    // Check limit
    if (record.requests.length > max) {
    Use Redis for distributed environments**: Ensures consistent limits across multiple instances
</Callout>

<Callout type="tip">
  **Different limits for different endpoints**: Protect sensitive operations with stricter limits
</Callout>

<Callout type="tip">
  **Always add headers**: Help clients understand the limits
</Callout>

<Callout type="warn">
  **Be careful with proxies**: Use `req.ip` which considers X-Forwarded-For headers
</Callout>

<Callout type="warn">
  **Don't block everything**: Whitelist internal and monitoring IPs

## Rate Limit per Endpoint üõ£Ô∏è

Different limits for different endpoints:

```typescript
@Controller("/api")
export class ApiController {
  @Post("/expensive-operation")
  expensiveOp(@Req() req: RequestServer, @Res() res: ResponseServer) {
    // Check specific rate limit
    const key = `expensive:${req.ip}`;
    const limit = checkRateLimit(key, 600000, 5);  // 5 per 10 min
    
    if (!limit.allowed) {
      return res.status(429).json({
        error: "Operation limited to 5 per 10 minutes"
      });
    }
    
    // Execute operation
    return { result: "ok" };
  }

  @Get("/public-data")
  publicData(@Req() req: RequestServer, @Res() res: ResponseServer) {
    // More permissive rate limit
    const key = `public:${req.ip}`;
    const limit = checkRateLimit(key, 60000, 1000);  // 1000 per min
    
    if (!limit.allowed) {
      return res.status(429).json({ error: "Rate limit exceeded" });
    }
    
    return { data: "public" };
  }
}

function checkRateLimit(key: string, windowMs: number, max: number) {
  // Implementation similar to previous examples
  // ...
  return { allowed: true, remaining: max };
}
```

## Whitelist and Blacklist üìù

Skip rate limiting for trusted IPs:

```typescript
const WHITELISTED_IPS = new Set([
  "127.0.0.1",
  "::1",
  "10.0.0.1"  // Internal IP
]);

const BLACKLISTED_IPS = new Set([
  "192.168.1.100"  // Banned IP
]);

function rateLimitWithWhitelist(
  windowMs: number,
  max: number
) {
  return (req: RequestServer, res: ResponseServer, next: () => void) => {
    const ip = req.ip;
    
    // Block banned IPs
    if (BLACKLISTED_IPS.has(ip)) {
      return res.status(403).json({ error: "IP banned" });
    }
    
    // Skip rate limit for trusted IPs
    if (WHITELISTED_IPS.has(ip)) {
      return next();
    }
    
    // Apply normal rate limit
    // ... rate limit implementation
    next();
  };
}

app.use(rateLimitWithWhitelist(60000, 100));
```

## Rate Limit Headers üìã

Add informative headers:

```typescript
function addRateLimitHeaders(
  res: ResponseServer,
  limit: number,
  remaining: number,
  resetAt: number
) {
  res.setHeader("X-RateLimit-Limit", limit.toString());
  res.setHeader("X-RateLimit-Remaining", remaining.toString());
  res.setHeader("X-RateLimit-Reset", resetAt.toString());
  res.setHeader("Retry-After", Math.ceil((resetAt - Date.now()) / 1000).toString());
}
```

## Practical Examples üé®

### Rate Limit for REST API

```typescript
const app = new AzuraClient({
  plugins: {
    rateLimit: {
      enabled: true,
      windowMs: 900000,  // 15 minutes
      max: 1000,
      headers: true
    }
  }
});

// Stricter rate limit for write operations
const writeRateLimit = rateLimitMiddleware(60000, 50);  // 50 writes/min

app.use("/api", apiRateLimit);
app.post("*", writeRateLimit);
app.put("*", writeRateLimit);
app.delete("*", writeRateLimit);
```

### Rate Limit for Authentication

```typescript
const authRateLimit = rateLimitMiddleware(900000, 5);  // 5 attempts/15min

@Controller("/auth")
export class AuthController {
  @Post("/login")
  async login(
    @Body() credentials: any,
    @Req() req: RequestServer,
    @Res() res: ResponseServer
  ) {
    // Check rate limit manually
    const key = `login:${req.ip}`;
    const limit = checkRateLimit(key, 900000, 5);
    
    if (!limit.allowed) {
      return res.status(429).json({
        error: "Too many login attempts",
        retryAfter: limit.retryAfter
      });
    }
    
    // Try to authenticate
    const user = await authenticate(credentials);
    
    if (!user) {
      return res.status(401).json({ error: "Invalid credentials" });
    }
    
    res.json({ user });
  }
}
```

## Response Headers üìã

Standard rate limit headers:

```typescript
res.setHeader("X-RateLimit-Limit", "100");         // Total allowed
res.setHeader("X-RateLimit-Remaining", "95");       // Remaining requests
res.setHeader("X-RateLimit-Reset", "1704067200");   // Unix timestamp
res.setHeader("Retry-After", "60");                 // Seconds to wait
```

## Bypass Rate Limiting üîì

Allow certain IPs or users to bypass:

```typescript
const whitelist = new Set(["127.0.0.1", "::1"]);
const apiKeys = new Set([process.env.ADMIN_API_KEY]);

export function createRateLimiterWithBypass(
  limit: number,
  windowMs: number
): RequestHandler {
  const limiter = createRateLimiter(limit, windowMs);
  
  return async (req, res, next) => {
    const ip = req.socket.remoteAddress || "";
    const apiKey = req.headers["x-api-key"] as string;
    
    // Bypass for whitelisted IPs
    if (whitelist.has(ip)) {
      await next();
      return;
    }
    
    // Bypass for API keys
    if (apiKey && apiKeys.has(apiKey)) {
      await next();
      return;
    }
    
    // Apply rate limiting
    await limiter(req, res, next);
  };
}
```

## Monitoring and Analytics üìä

### Track Rate Limit Hits

```typescript
import { Logger } from "azurajs/logger";

function createRateLimiterWithMonitoring(
  limit: number,
  windowMs: number
): RequestHandler {
  const store = new Map<string, RateLimitStore>();
  
  return async (req, res, next) => {
    const ip = req.socket.remoteAddress || "unknown";
    const now = Date.now();
    
    let record = store.get(ip);
    
    if (!record || now > record.resetTime) {
      record = { count: 1, resetTime: now + windowMs };
      store.set(ip, record);
      await next();
      return;
    }
    
    record.count++;
    
    if (record.count > limit) {
      // Log rate limit hit for monitoring
      Logger.warn("Rate limit exceeded", {
        ip,
        path: req.url,
        method: req.method,
        count: record.count,
        limit,
        timestamp: new Date().toISOString()
      });
      
      res.status(429).json({
        error: "Too many requests",
        retryAfter: Math.ceil((record.resetTime - now) / 1000)
      });
      return;
    }
    
    await next();
  };
}
```

### Metrics Collection

```typescript
interface RateLimitMetrics {
  totalRequests: number;
  blockedRequests: number;
  topOffenders: Map<string, number>;
}

const metrics: RateLimitMetrics = {
  totalRequests: 0,
  blockedRequests: 0,
  topOffenders: new Map()
};

function updateMetrics(ip: string, blocked: boolean) {
  metrics.totalRequests++;
  if (blocked) {
    metrics.blockedRequests++;
    const count = metrics.topOffenders.get(ip) || 0;
    metrics.topOffenders.set(ip, count + 1);
  }
}

// Expose metrics endpoint
@Get("/metrics/rate-limits")
getRateLimitMetrics(@Res() res: ResponseServer) {
  const topOffenders = Array.from(metrics.topOffenders.entries())
    .sort((a, b) => b[1] - a[1])
    .slice(0, 10);
  
  res.json({
    totalRequests: metrics.totalRequests,
    blockedRequests: metrics.blockedRequests,
    blockRate: (metrics.blockedRequests / metrics.totalRequests * 100).toFixed(2) + '%',
    topOffenders: Object.fromEntries(topOffenders)
  });
}
```

## Testing Rate Limits üß™

### Manual Testing

```bash
# Test with curl
for i in {1..150}; do
  curl -w "\\n%{http_code}" https://api.example.com/test
  sleep 0.1
done

# Should see:
# 200 (requests 1-100)
# 429 (requests 101+)
```

### Automated Testing

```typescript
import { describe, it, expect } from "@jest/globals";

describe("Rate Limiting", () => {
  it("should allow requests under limit", async () => {
    for (let i = 0; i < 10; i++) {
      const response = await fetch("http://localhost:3000/api/test");
      expect(response.status).toBe(200);
    }
  });
  
  it("should block requests over limit", async () => {
    // Make 100 requests to hit limit
    for (let i = 0; i < 100; i++) {
      await fetch("http://localhost:3000/api/test");
    }
    
    // Next request should be blocked
    const response = await fetch("http://localhost:3000/api/test");
    expect(response.status).toBe(429);
    
    // Check headers
    expect(response.headers.get("X-RateLimit-Remaining")).toBe("0");
    expect(response.headers.get("Retry-After")).toBeTruthy();
  });
  
  it("should reset after time window", async () => {
    // Hit limit
    for (let i = 0; i < 100; i++) {
      await fetch("http://localhost:3000/api/test");
    }
    
    // Wait for window to reset (e.g., 60 seconds)
    await new Promise(resolve => setTimeout(resolve, 61000));
    
    // Should work again
    const response = await fetch("http://localhost:3000/api/test");
    expect(response.status).toBe(200);
  });
});
```

## Dynamic Rate Limits Based on Load üéöÔ∏è

```typescript
interface SystemLoad {
  cpu: number;
  memory: number;
}

function getSystemLoad(): SystemLoad {
  // Simplified - use actual monitoring tools in production
  return {
    cpu: Math.random() * 100,
    memory: Math.random() * 100
  };
}

function createAdaptiveRateLimiter(
  baseLimit: number,
  windowMs: number
): RequestHandler {
  return async (req, res, next) => {
    const load = getSystemLoad();
    
    // Reduce limit when system is under stress
    let adjustedLimit = baseLimit;
    
    if (load.cpu > 80 || load.memory > 80) {
      adjustedLimit = Math.floor(baseLimit * 0.5);  // Reduce to 50%
    } else if (load.cpu > 60 || load.memory > 60) {
      adjustedLimit = Math.floor(baseLimit * 0.75);  // Reduce to 75%
    }
    
    // Apply rate limiting with adjusted limit
    const limiter = createRateLimiter(adjustedLimit, windowMs);
    await limiter(req, res, next);
  };
}

app.use(createAdaptiveRateLimiter(1000, 60000));
```

## Best Practices ‚ú®

<Callout type="tip">
  **Start conservative** - Begin with stricter limits and relax based on usage
</Callout>

<Callout type="tip">
  **Use appropriate windows** - Shorter windows for sensitive endpoints
</Callout>

<Callout type="warn">
  **Consider legitimate spikes** - Don't set limits too low
</Callout>

<Callout type="info">
  **Monitor and adjust** - Track 429 responses and adjust limits accordingly
</Callout>
CORS" href="cors" description="Configure CORS" />
- [Middleware](/docs/middleware) - Learn more about middleware
- [Error Handling](/docs/error-handling) - Handle rate limit errors
- [Performance](/docs/performance) - Optimize your API
